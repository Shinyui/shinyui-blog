---
title: è™•ç†è³‡æ–™ç¼ºå¤±å€¼çš„æ–¹æ³• â€” å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•åŠPythonå¯¦ä½œ
description: è™•ç†è³‡æ–™ç¼ºå¤±å€¼çš„æ–¹æ³• â€” å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•åŠPythonå¯¦ä½œ
slug: mean-mode-imputation
date: 2020-09-28
type: Post
---

## è™•ç†è³‡æ–™ç¼ºå¤±å€¼çš„æ–¹æ³• â€” å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•åŠ Python å¯¦ä½œ

åœ¨ä¸Šä¸€ç¯‡æˆ‘å€‘æœ‰æåˆ°å¦‚ä½•åˆ©ç”¨[å®Œæ•´è³‡æ–™åˆ†æï¼ˆCCAï¼‰](https://medium.com/%E4%BA%82%E9%BB%9E%E6%8A%80%E8%83%BD%E6%A8%B9%E7%9A%84%E4%BA%BA%E7%94%9F/%E8%99%95%E7%90%86%E8%B3%87%E6%96%99%E7%BC%BA%E5%A4%B1%E5%80%BC%E7%9A%84%E6%96%B9%E6%B3%95-%E5%AE%8C%E6%95%B4%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-complete-case-analysis-%E5%8F%8Apython%E5%AF%A6%E4%BD%9C-798d466ec4b7)ä¾†è™•ç†è³‡æ–™ç¼ºå¤±çš„å•é¡Œï¼Œæˆ‘å€‘çŸ¥é“å®Œæ•´è³‡æ–™åˆ†æï¼ˆCCAï¼‰çš„ä½¿ç”¨å‰ææ˜¯è³‡æ–™çš„ç¼ºå¤±æ˜¯éš¨æ©Ÿçš„ï¼ˆMCARï¼‰ï¼Œè€Œä¸”ç¼ºå¤±æ¯”ä¾‹ä¸èƒ½å¤§æ–¼ 5%ã€‚ä½†æ˜¯é™¤äº†å®Œæ•´è³‡æ–™åˆ†æå¤–æˆ‘å€‘é‚„æœ‰å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•ï¼ˆMean/Median Imputationï¼‰å¯ä»¥åˆ©ç”¨ï¼Œåœ¨é€™é‚Šæˆ‘å€‘æœƒä»‹ç´¹é€™å…©ç¨®å·®å€¼æ³•çš„å‡è¨­ã€å„ªç¼ºé»åŠ Python å¯¦ä½œã€‚

## ä»€éº¼æ˜¯æ’å€¼æ³•ï¼ˆImputationï¼‰ï¼Ÿ

> # æ’å€¼æ³•çš„æ¦‚å¿µå…¶å¯¦å¾ˆç°¡å–®ï¼Œå°±æ˜¯æŠŠç¼ºå¤±çš„æ•¸å€¼ç”¨æŸå€‹æ•¸å­—è£œèµ·ä¾†ã€‚

é‚£è‡³æ–¼é€™å€‹æ•¸å­—æ˜¯ä»€éº¼ï¼Ÿå¯ä»¥æ˜¯ç”±æŸå€‹å…¬å¼æˆ–æ˜¯ä½ è‡ªå·±æ±ºå®šè¦æ’å…¥ä»€éº¼æ•¸å­—ï¼

## å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•æ˜¯ä»€éº¼ï¼Ÿ

åœ¨ä¸Šä¸€æ®µæˆ‘å€‘çŸ¥é“æ’å€¼æ³•çš„æ¦‚å¿µå°±æ˜¯æŠŠç¼ºå¤±çš„å€¼ç”¨æŸå€‹æ•¸å­—è£œä¸Šå»ï¼Œè€Œå¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•æ˜¯å…¶ä¸­æœ€å¸¸ç”¨çš„æ–¹æ³•ä¹‹ä¸€ã€‚å¾åå­—æ‡‰è©²å¯ä»¥çœ‹å‡ºå¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•å°±æ˜¯æŠŠç¼ºå¤±å€¼ç”¨å¹³å‡æ•¸æˆ–ä¸­ä½æ•¸çµ¦è£œèµ·ä¾†ã€‚

é‚£ä»€éº¼æ™‚å€™è©²ç”¨å¹³å‡æ•¸è·Ÿä¸­ä½æ•¸å‘¢ï¼Ÿæˆ‘å€‘å¯ä»¥å¾è³‡æ–™çš„æˆ‘å€‘å¯ä»¥å¾è³‡æ–™çš„åæ…‹ä¾†äº†è§£~

![](https://cdn-images-1.medium.com/max/2000/0*badfK2o6IFvVOmgW)

æˆ‘å€‘å¯ä»¥çœ‹åˆ°ç•¶è³‡æ–™æ˜¯å¸¸æ…‹åˆ†ä½ˆæ™‚æˆ‘å€‘å¯ä»¥åˆ©ç”¨å¹³å‡æ•¸è·Ÿä¸­ä½æ•¸å› ç‚ºé€™å…©å€‹æ•¸å­—åŸºæœ¬ä¸Šå·®ç•°ä¸å¤§ï¼Œä½†æ˜¯ç•¶è³‡æ–™å‘ˆç¾è² åæ…‹çš„æ™‚å€™ç”¨ä¸­ä½æ•¸æœƒæ›´è²¼è¿‘ç¾å¯¦ï¼Œå› ç‚ºå¹³å‡æ•¸æœƒè¢«é›¢ç¾¤å€¼å½±éŸ¿ï¼Œç›¸å°çš„ç•¶è³‡æ–™å‘ˆç¾æ­£åæ…‹çš„æ™‚å€™ä½¿ç”¨ä¸­ä½æ•¸ä¹Ÿæ˜¯ä¸€å€‹è¼ƒå¥½çš„é¸æ“‡ã€‚

## å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•çš„å‡è¨­åŠé©ç”¨æƒ…æ³

å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•çš„å‡è¨­æ˜¯è³‡æ–™çš„ç¼ºå¤±æƒ…æ³å¿…é ˆæ˜¯ Missing Completely at Random çš„æƒ…æ³ä¸‹æ‰èƒ½ä½¿ç”¨å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•ï¼ŒåŒæ™‚é€™å€‹æ–¹æ³•çš„å‡è¨­æ˜¯ç¼ºå¤±çš„è³‡æ–™æœƒè·Ÿå¤šæ•¸è³‡æ–™é•·å¾—å·®ä¸å¤šï¼ˆå¹³å‡æ•¸æˆ–æ˜¯ä¸­ä½æ•¸ï¼‰ã€‚

ä½¿ç”¨é€™å€‹æ–¹æ³•çš„å¥½è™•æ˜¯èƒ½å¤ å¿«é€Ÿåœ°è¢«å¯¦è¸å‡ºä¾†ï¼Œä½†æ˜¯é€™å€‹æ–¹æ³•æœƒç ´å£ï¼ˆDistortï¼‰åŸå§‹è³‡æ–™çš„åˆ†å¸ƒç‹€æ³ï¼ˆDistributionï¼‰ã€è®Šç•°æ•¸ï¼ˆVarianceï¼‰é‚„æœ‰èˆ‡å…¶ä»–è®Šæ•¸çš„å…±è®Šç•°æ•¸ï¼ˆCovarianceï¼‰ã€‚

æ¯”ä¾‹çš„è©±è·Ÿå®Œæ•´è³‡æ–™åˆ†æç›¸åŒï¼Œå¤§ç´„æ˜¯ 5%çš„ç¼ºå¤±è³‡æ–™æœƒå¯ä»¥é©ç”¨å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•ã€‚ç¼ºå¤±æ¯”ä¾‹è¶Šé«˜ï¼Œæ¡ç”¨é€™å€‹æ–¹æ³•æœƒä½¿å¾—è³‡æ–™åˆ†å¸ƒç‹€æ³ï¼ˆDistributionï¼‰ã€è®Šç•°æ•¸ï¼ˆVarianceï¼‰é‚„æœ‰èˆ‡å…¶ä»–è®Šæ•¸çš„å…±è®Šç•°æ•¸ï¼ˆCovarianceï¼‰è¢«ç ´å£çš„ç¨‹åº¦è¶Šåš´é‡ã€‚

é€™é‚Šè¦æ³¨æ„çš„æ˜¯å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•ï¼Œ**åªèƒ½åœ¨è¨“ç·´é›†ä¸Šåšè¨ˆç®—**ï¼Œç„¶å¾Œå†å°‡çµæœå¥—ç”¨åœ¨æ¸¬è©¦é›†ä¸Šã€‚æ›å¥æˆ–èªªï¼Œæˆ‘å€‘è¦å…ˆé‡å°åŸå§‹è³‡æ–™åš train_test_split ç„¶å¾ŒæŠŠè¨“ç·´é›†çš„è³‡æ–™ä½œå¹³å‡æ•¸æˆ–æ˜¯ä¸­ä½æ•¸çš„è¨ˆç®—ï¼ˆä¹Ÿå°±æ˜¯ fitï¼‰ï¼Œæœ€å¾ŒæŠŠçµæœ transform åœ¨è¨“ç·´é›†è·Ÿæ¸¬è©¦é›†ä¸Šã€‚

é€™é‚Šæˆ‘å€‘ç”¨ç°¡å–®çš„ç¨‹å¼ç¢¼ä¾†ä½œç¯„ä¾‹

```Python
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split

df = pd.read_csv("your_csv_file.csv")

X = df.drop("target_variable", axis=1)
y = df["target_variable"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

imp = SimpleImputer(missing_values=np.nan, strategy='mean')
imp.fit(X_train)
X_train = imp.transform(X_train)
X_test = imp.transform(X_test)
```

é€™æ¨£ä¸€ä¾†å°±å¯ä»¥é˜²æ­¢è³‡æ–™æ´©æ¼ï¼ˆData Leakageï¼‰æ‰€é€ æˆçš„æ¨¡å‹éæ“¬åˆï¼ˆOver-fittingï¼‰ï¼Œé—œæ–¼é€™å€‹å•é¡Œçš„æ·±åº¦è§£é‡‹æˆ‘å€‘ä¹‹å¾Œæœƒå¯«ä¸€ç¯‡æ–‡ç« ä¾†è§£é‡‹ä»€éº¼å«åšè³‡æ–™æ´©æ¼ã€ç‚ºä»€éº¼æœƒé€ æˆéæ“¬åˆä»¥åŠå¦‚ä½•é é˜²~~

## å¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³• Python å¯¦ä½œ

æ¥ä¸‹ä¾†æˆ‘å€‘è¦è«‡è«‡å¦‚ä½•åœ¨ Pytho å¯¦ä½œå¹³å‡æ•¸èˆ‡ä¸­ä½æ•¸æ’å€¼æ³•ï¼Œè·Ÿä¸Šä¸€ç¯‡æ–‡ç« ä¸€æ¨£æˆ‘å€‘ä½¿ç”¨çš„æ˜¯ Kaggle çš„ House Prices: Advanced Regression Techniques é€™å€‹æ¯”è³½çš„**è¨“ç·´è³‡æ–™é›†ã€‚**

å…ˆå‰å·²ç¶“æœ‰æéå¦‚ä½•ç¯©é¸å‡ºç¼ºå¤±å€¼çš„è³‡æ–™ï¼Œé€™é‚Šå°±ä¸å†è´…è¿°äº†ã€‚åŸºæœ¬ä¸Šæˆ‘å€‘å¯ä»¥åˆ©ç”¨ä»¥ä¸‹ç¨‹å¼ç¢¼å°‡**æœ‰ç¼ºå¤±è³‡æ–™çš„è®Šæ•¸ä»¥**åŠ**ç¼ºå¤±çš„æ¯”ä¾‹**çµ¦è¨ˆç®—å‡ºä¾†ã€‚

```Python
    df.isnull().mean()
```

åœ¨é€™å€‹ç¯„ä¾‹ä¸­æˆ‘å€‘æœƒåˆ©ç”¨"MasVnrArea", "GarageYrBlt"é‚„æœ‰"LotFrontage"é€™ä¸‰å€‹è®Šæ•¸ä¾†ç¤ºç¯„ï¼Œæˆ‘å€‘å…ˆä¾†çœ‹ä¸€ä¸‹é€™ä¸‰å€‹è®Šæ•¸çš„ç¼ºå¤±è³‡æ–™æ¯”ä¾‹æœ‰å¤šå°‘ï¼Œæˆ‘å€‘å¯ä»¥åˆ©ç”¨é€™å€‹ç¨‹å¼ç¢¼ä¾†é”æˆã€‚

```Python
    df = df[["MasVnrArea", "GarageYrBlt", "LotFrontage", "SalePrice"]]
    df.isnull().mean()*100
```

çµæœå¦‚ä¸‹

![](https://cdn-images-1.medium.com/max/2000/1*kzbCnGnXstOTUjnL1LsqRg.png)

æˆ‘å€‘å¯ä»¥çœ‹åˆ°é€™ 3 å€‹è®Šæ•¸çš„ç¼ºå¤±æ¯”ä¾‹å¾ 0.5% ~ 17.7%éƒ½æœ‰ï¼ŒæŒ‘é¸é€™ 3 å€‹è®Šæ•¸çš„ä¸»è¦åŸå› æ˜¯ç¨å¾Œæƒ³è®“å¤§å®¶äº†è§£ä¸åŒç¼ºå¤±æ¯”ä¾‹ä¸‹çš„è®Šç•°ç¨‹åº¦æœ‰å¤šå°‘ã€‚è€Œ SalesPrice å‰‡æ˜¯æˆ‘å€‘è¦é æ¸¬çš„æ•¸å­—ï¼Œä¿ç•™å®ƒæ˜¯å› ç‚ºæˆ‘å€‘ç¨å¾Œè¦åš train_test_splitã€‚

æˆ‘å€‘æ¥è‘—ä¾†æŠŠè³‡æ–™åšæ‹†åˆ†ï¼Œæˆ‘å€‘å¯ä»¥åˆ©ç”¨ä¸‹é¢é€™è¡Œç¨‹å¼ç¢¼ä¾†é”æˆ

```Python
from sklearn.model_selection import train_test_split

X = df.drop(â€œSalePriceâ€, axis=1)
y = df[â€œSalePriceâ€]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```

æ¥è‘—ä¾†åšä¸­ä½æ•¸æ’å€¼æ³•ï¼Œæ¡ç”¨é€™å€‹æ–¹æ³•çš„åŸå› æ˜¯è³‡æ–™ä¸æ˜¯å¸¸æ…‹åˆ†å¸ƒï¼Œæˆ‘å€‘å¯ä»¥ç”¨ä»¥ä¸‹ç¨‹å¼ç¢¼ç•«å€‹ç°¡å–®çš„åœ–è¡¨ä½œåˆ†æ

```Python
f, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))
ax = ax.flatten()

sns.distplot(X_train[â€œMasVnrAreaâ€], ax=ax[0])
sns.distplot(X_train[â€œGarageYrBltâ€], ax=ax[1])
sns.distplot(X_train[â€œLotFrontageâ€], ax=ax[2])
```

è¼¸å‡ºæœƒé•·é€™æ¨£ï¼Œè »æ˜é¡¯ä¸æ˜¯å¸¸æ…‹åˆ†ä½ˆï¼Œæ‰€ä»¥æ¡ç”¨ä¸­ä½æ•¸æ’å€¼æ³•

![](https://cdn-images-1.medium.com/max/4688/1*ENmfqpEsdbRKdf7kANs7cg.png)

æ¥è‘—ä¾†æ’æ•¸å­—ï¼Œç¨‹å¼ç¢¼æœƒé•·ä¸‹é¢é€™æ¨£

```Python
import numpy as np
from sklearn.impute import SimpleImputer

imp = SimpleImputer(missing_values=np.nan, strategy=â€™medianâ€™)

imp.fit(X_train)
X_train_transformed = imp.transform(X_train)

X_train_transformed = pd.DataFrame(X_train_transformed, columns=df.columns[0: -1])
```

åœ¨æœ€å¾Œä¸€è¡Œæˆ‘å€‘æŠŠ transformed å®Œæˆçš„è³‡æ–™è½‰è®Šæˆ dataframe æ˜¯ç‚ºäº†å¾ŒçºŒä½œåœ–æ–¹ä¾¿ï¼Œå› ç‚º transform å®Œçš„è³‡æ–™æœƒå›å‚³ array è€Œä¸æ˜¯ dataframeã€‚

æ¥è‘—æˆ‘å€‘å…ˆå¾è®Šç•°æ•¸ä¾†æ¯”è¼ƒå…¶å¾Œçš„å·®ç•°ï¼Œç¨‹å¼ç¢¼å¦‚ä¸‹

```Python
for col in X_train.columns:
    print(f"col {col}'s variance is {np.var(X_train[col])} before median imputation")
    print(f"col {col}'s variance is {np.var(X_train_transformed[col])} after median imputation")
    print(f"difference is {abs(np.var(X_train_transformed[col]) - np.var(X_train[col]))}\n")
```

è¼¸å‡ºçµæœ

![](https://cdn-images-1.medium.com/max/2478/1*Ps3PEa53johIES0-zwyUDg.png)

æˆ‘å€‘å¯ä»¥çœ‹åˆ°ï¼Œå³ä¾¿åªæœ‰ç¼ºå¤± 0.5%çš„è³‡æ–™ï¼Œç¶“éä¸­ä½æ•¸æ’å€¼æ³•å¾Œè®Šç•°æ•¸å·®ç•°ä¹Ÿæœƒé”åˆ° 55ã€‚

æ¥è‘—ä¾†çœ‹åœ–ï¼Œç¨‹å¼ç¢¼å¦‚ä¸‹

```Python
f, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))
ax = ax.flatten()

sns.distplot(X_train["MasVnrArea"], ax=ax[0], label="before imputation")
sns.distplot(X_train_transformed["MasVnrArea"], ax=ax[0], label="after imputation")
sns.distplot(X_train["GarageYrBlt"], ax=ax[1], label="before imputation")
sns.distplot(X_train_transformed["GarageYrBlt"], ax=ax[1], label="after imputation")
sns.distplot(X_train["LotFrontage"], ax=ax[2], label="before imputation")
sns.distplot(X_train_transformed["LotFrontage"], ax=ax[2], label="after imputation")

plt.legend()
```

çµæœå¦‚ä¸‹

![](https://cdn-images-1.medium.com/max/4650/1*uuRF5A5XXdBhkFitgMOgTQ.png)

æˆ‘å€‘å¯ä»¥çœ‹åˆ°ï¼Œä½¿ç”¨é€™å€‹æ’å€¼æ³•çš„å‰å¾Œï¼Œæœƒå°è³‡æ–™çš„åˆ†å¸ƒç‹€æ³é€ æˆä¸€å®šå½±éŸ¿çš„ï¼Œå°¤å…¶æ˜¯ç¼ºå¤±å€¼æ¯”ä¾‹è¶Šå¤§çš„æ™‚å€™è¶Šåš´é‡ï¼

## ä½ å–œæ­¡å—ï¼Ÿ

å–œæ­¡çš„è©±å¯ä»¥åˆ†äº«å‡ºå»ï¼Œå¦‚æœä¸å–œæ­¡å°±â€¦â€¦ç®—äº†ï¼Œæˆ‘é‚„æ˜¯æœƒç¹¼çºŒå¯« ğŸ˜‚ã€‚
