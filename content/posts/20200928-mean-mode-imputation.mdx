---
title: 處理資料缺失值的方法 — 平均數與中位數插值法及Python實作
description: 處理資料缺失值的方法 — 平均數與中位數插值法及Python實作
slug: mean-mode-imputation
date: 2020-09-28
type: Post
---

## 處理資料缺失值的方法 — 平均數與中位數插值法及 Python 實作

在上一篇我們有提到如何利用[完整資料分析（CCA）](https://medium.com/%E4%BA%82%E9%BB%9E%E6%8A%80%E8%83%BD%E6%A8%B9%E7%9A%84%E4%BA%BA%E7%94%9F/%E8%99%95%E7%90%86%E8%B3%87%E6%96%99%E7%BC%BA%E5%A4%B1%E5%80%BC%E7%9A%84%E6%96%B9%E6%B3%95-%E5%AE%8C%E6%95%B4%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-complete-case-analysis-%E5%8F%8Apython%E5%AF%A6%E4%BD%9C-798d466ec4b7)來處理資料缺失的問題，我們知道完整資料分析（CCA）的使用前提是資料的缺失是隨機的（MCAR），而且缺失比例不能大於 5%。但是除了完整資料分析外我們還有平均數與中位數插值法（Mean/Median Imputation）可以利用，在這邊我們會介紹這兩種差值法的假設、優缺點及 Python 實作。

## 什麼是插值法（Imputation）？

> # 插值法的概念其實很簡單，就是把缺失的數值用某個數字補起來。

那至於這個數字是什麼？可以是由某個公式或是你自己決定要插入什麼數字！

## 平均數與中位數插值法是什麼？

在上一段我們知道插值法的概念就是把缺失的值用某個數字補上去，而平均數與中位數插值法是其中最常用的方法之一。從名字應該可以看出平均數與中位數插值法就是把缺失值用平均數或中位數給補起來。

那什麼時候該用平均數跟中位數呢？我們可以從資料的我們可以從資料的偏態來了解~

![](https://cdn-images-1.medium.com/max/2000/0*badfK2o6IFvVOmgW)

我們可以看到當資料是常態分佈時我們可以利用平均數跟中位數因為這兩個數字基本上差異不大，但是當資料呈現負偏態的時候用中位數會更貼近現實，因為平均數會被離群值影響，相對的當資料呈現正偏態的時候使用中位數也是一個較好的選擇。

## 平均數與中位數插值法的假設及適用情況

平均數與中位數插值法的假設是資料的缺失情況必須是 Missing Completely at Random 的情況下才能使用平均數與中位數插值法，同時這個方法的假設是缺失的資料會跟多數資料長得差不多（平均數或是中位數）。

使用這個方法的好處是能夠快速地被實踐出來，但是這個方法會破壞（Distort）原始資料的分布狀況（Distribution）、變異數（Variance）還有與其他變數的共變異數（Covariance）。

比例的話跟完整資料分析相同，大約是 5%的缺失資料會可以適用平均數與中位數插值法。缺失比例越高，採用這個方法會使得資料分布狀況（Distribution）、變異數（Variance）還有與其他變數的共變異數（Covariance）被破壞的程度越嚴重。

這邊要注意的是平均數與中位數插值法，**只能在訓練集上做計算**，然後再將結果套用在測試集上。換句或說，我們要先針對原始資料做 train_test_split 然後把訓練集的資料作平均數或是中位數的計算（也就是 fit），最後把結果 transform 在訓練集跟測試集上。

這邊我們用簡單的程式碼來作範例

```Python
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split

df = pd.read_csv("your_csv_file.csv")

X = df.drop("target_variable", axis=1)
y = df["target_variable"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)

imp = SimpleImputer(missing_values=np.nan, strategy='mean')
imp.fit(X_train)
X_train = imp.transform(X_train)
X_test = imp.transform(X_test)
```

這樣一來就可以防止資料洩漏（Data Leakage）所造成的模型過擬合（Over-fitting），關於這個問題的深度解釋我們之後會寫一篇文章來解釋什麼叫做資料洩漏、為什麼會造成過擬合以及如何預防~~

## 平均數與中位數插值法 Python 實作

接下來我們要談談如何在 Pytho 實作平均數與中位數插值法，跟上一篇文章一樣我們使用的是 Kaggle 的 House Prices: Advanced Regression Techniques 這個比賽的**訓練資料集。**

先前已經有提過如何篩選出缺失值的資料，這邊就不再贅述了。基本上我們可以利用以下程式碼將**有缺失資料的變數以**及**缺失的比例**給計算出來。

```Python
    df.isnull().mean()
```

在這個範例中我們會利用"MasVnrArea", "GarageYrBlt"還有"LotFrontage"這三個變數來示範，我們先來看一下這三個變數的缺失資料比例有多少，我們可以利用這個程式碼來達成。

```Python
    df = df[["MasVnrArea", "GarageYrBlt", "LotFrontage", "SalePrice"]]
    df.isnull().mean()*100
```

結果如下

![](https://cdn-images-1.medium.com/max/2000/1*kzbCnGnXstOTUjnL1LsqRg.png)

我們可以看到這 3 個變數的缺失比例從 0.5% ~ 17.7%都有，挑選這 3 個變數的主要原因是稍後想讓大家了解不同缺失比例下的變異程度有多少。而 SalesPrice 則是我們要預測的數字，保留它是因為我們稍後要做 train_test_split。

我們接著來把資料做拆分，我們可以利用下面這行程式碼來達成

```Python
from sklearn.model_selection import train_test_split

X = df.drop(“SalePrice”, axis=1)
y = df[“SalePrice”]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```

接著來做中位數插值法，採用這個方法的原因是資料不是常態分布，我們可以用以下程式碼畫個簡單的圖表作分析

```Python
f, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))
ax = ax.flatten()

sns.distplot(X_train[“MasVnrArea”], ax=ax[0])
sns.distplot(X_train[“GarageYrBlt”], ax=ax[1])
sns.distplot(X_train[“LotFrontage”], ax=ax[2])
```

輸出會長這樣，蠻明顯不是常態分佈，所以採用中位數插值法

![](https://cdn-images-1.medium.com/max/4688/1*ENmfqpEsdbRKdf7kANs7cg.png)

接著來插數字，程式碼會長下面這樣

```Python
import numpy as np
from sklearn.impute import SimpleImputer

imp = SimpleImputer(missing_values=np.nan, strategy=’median’)

imp.fit(X_train)
X_train_transformed = imp.transform(X_train)

X_train_transformed = pd.DataFrame(X_train_transformed, columns=df.columns[0: -1])
```

在最後一行我們把 transformed 完成的資料轉變成 dataframe 是為了後續作圖方便，因為 transform 完的資料會回傳 array 而不是 dataframe。

接著我們先從變異數來比較其後的差異，程式碼如下

```Python
for col in X_train.columns:
    print(f"col {col}'s variance is {np.var(X_train[col])} before median imputation")
    print(f"col {col}'s variance is {np.var(X_train_transformed[col])} after median imputation")
    print(f"difference is {abs(np.var(X_train_transformed[col]) - np.var(X_train[col]))}\n")
```

輸出結果

![](https://cdn-images-1.medium.com/max/2478/1*Ps3PEa53johIES0-zwyUDg.png)

我們可以看到，即便只有缺失 0.5%的資料，經過中位數插值法後變異數差異也會達到 55。

接著來看圖，程式碼如下

```Python
f, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 5))
ax = ax.flatten()

sns.distplot(X_train["MasVnrArea"], ax=ax[0], label="before imputation")
sns.distplot(X_train_transformed["MasVnrArea"], ax=ax[0], label="after imputation")
sns.distplot(X_train["GarageYrBlt"], ax=ax[1], label="before imputation")
sns.distplot(X_train_transformed["GarageYrBlt"], ax=ax[1], label="after imputation")
sns.distplot(X_train["LotFrontage"], ax=ax[2], label="before imputation")
sns.distplot(X_train_transformed["LotFrontage"], ax=ax[2], label="after imputation")

plt.legend()
```

結果如下

![](https://cdn-images-1.medium.com/max/4650/1*uuRF5A5XXdBhkFitgMOgTQ.png)

我們可以看到，使用這個插值法的前後，會對資料的分布狀況造成一定影響的，尤其是缺失值比例越大的時候越嚴重！

## 你喜歡嗎？

喜歡的話可以分享出去，如果不喜歡就……算了，我還是會繼續寫 😂。
